# -*- coding: utf-8 -*-
# Created: 2025/10/31
# 5.1_titles_normalize.py
"""
=============================================================
æ ‡é¢˜ç­‰çº§æ¢³ç†è„šæœ¬ï¼ˆé€è¡Œè¯†åˆ«ç‰ˆ + ä¿®æ­£ç‰ˆåŠ ç²—é€»è¾‘ï¼‰
Version: 5_titles_normalize_v12.py
=============================================================
"""

import os
import re
import csv
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parents[1]))  # æ·»åŠ çˆ¶ç›®å½•
# âœ… æ–°å¢ï¼šå¯¼å…¥ç»Ÿä¸€çš„æ–‡ä»¶I/Oä¸æ—¥å¿—æ¨¡å—
from utils.template_script_header_manual import (
    load_text, save_text, log_stage, log_summary
)
# âœ… æ–°å¢ï¼šå¯¼å…¥æ­£åˆ™ç¯å¢ƒæ ‡å‡†åŒ–æ¨¡å—
from utils.text_normalizer import normalize_chinese_text

# ==========================================================
# è·¯å¾„é…ç½®
# ==========================================================
# âš™ï¸ ä¿®æ”¹ï¼šæ”¹ä¸º Path å¯¹è±¡ï¼Œç»Ÿä¸€è·¯å¾„é£æ ¼
INPUT_PATH    = Path(r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\åˆ†å·æ¸…æ´—\sichuan\Chinese Folk Tales_sichuan.md")
OUTPUT_TARGET = Path(r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\åˆ†å·æ¸…æ´—\sichuan\5.1_Chinese Folk Tales_sichuan.md")
CSV_PATH      = Path(r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\åˆ†å·æ¸…æ´—\sichuan\5.1_sichuan_heading_stats.csv")
CSV_EMPH_PATH = Path(r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\åˆ†å·æ¸…æ´—\sichuan\5.1_sichuan_emphasized_h1.csv")

DEBUG_SHOW_PER_LEVEL = 3

# ==========================================================
# å…¬å…±ç¬¦å·ä¸æ ‡é¢˜æ¨¡å¼
# ==========================================================
PUNCT_WS = r"\s,\.ï¼Œã€‚:ï¼š;ï¼›!ï¼\?ï¼ŸÂ·ãƒ»â€”\-_\~`'\"â€œâ€â€˜â€™\(\)ï¼ˆï¼‰\[\]ã€ã€‘<>ã€Šã€‹ã€â€¦â‹¯ï¼Â·"
ROM_NUMS = "ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒé›¶ã€‡â—‹"
RE_ALL_HASHES = re.compile(r"^\s{0,3}#{1,6}\s*")

def build_fuzzy_regex(text: str) -> re.Pattern:
    core = re.sub(f"[{PUNCT_WS}]", "", text)
    if not core:
        return re.compile(r"^(?!)$")
    sep = f"[{PUNCT_WS}]*"
    pattern = rf"^\s*[{PUNCT_WS}]*" + sep.join(map(re.escape, core)) + rf"[{PUNCT_WS}]*\s*$"
    return re.compile(pattern)

H1_TITLES = ["å‰è¨€", "åè®°", "ç¥è¯", "ä¼ è¯´", "æ•…äº‹"]
H2_TITLES = [
    "å¼€å¤©è¾Ÿåœ°ç¥è¯","å¤©åœ°å¼€è¾Ÿç¥è¯","è‡ªç„¶å¤©è±¡ç¥è¯","åŠ¨ç‰©æ¤ç‰©ç¥è¯","åŠ¨æ¤ç‰©ç¥è¯","å›¾è…¾ç¥–å…ˆç¥è¯","ç¥–å…ˆç¥è¯","å¤©ä½“è‡ªç„¶ç¥è¯",
    "æ´ªæ°´äººç±»å†ç¹è¡ç¥è¯","æ–‡åŒ–èµ·æºç¥è¯","æ–‡åŒ–èµ·æºå’Œç¥–å…ˆç¥è¯","ç¥å’Œè‹±é›„ç¥è¯","è‹±é›„ç¥è¯",
    "äººç‰©ä¼ è¯´","ä¸‰å›½èœ€æ±‰äººç‰©ä¼ è¯´","æ–‡äººä¼ è¯´","ç°ä»£é©å‘½å®¶ä¼ è¯´",
    "å²äº‹ä¼ è¯´","åœ°æ–¹ä¼ è¯´","åå±±ä¼ è¯´","é£ä¿—ä¼ è¯´","åŠ¨æ¤ç‰©ä¼ è¯´","åŠ¨ç‰©æ¤ç‰©ä¼ è¯´","ä¸°éƒ½é¬¼åŸä¼ è¯´",
    "åœŸç‰¹äº§ä¼ è¯´","æ°‘é—´å·¥è‰ºä¼ è¯´",
    "åŠ¨ç‰©æ•…äº‹","å¹»æƒ³æ•…äº‹","é¬¼ç‹ç²¾æ€ªæ•…äº‹","ç”Ÿæ´»æ•…äº‹",
    "æœºæ™ºäººç‰©æ•…äº‹","å¯“è¨€æ•…äº‹","ç¬‘è¯","å¯“è¨€"
]

H1_PATTERNS = [build_fuzzy_regex(t) for t in H1_TITLES]
H2_PATTERNS = [build_fuzzy_regex(t) for t in H2_TITLES]
RE_H3_NUM_TITLE = re.compile(rf"^\s*(?P<num>\d{{1,5}})\s*[{PUNCT_WS}]*\s*(?P<title>.*[\u4e00-\u9fa5].*?)\s*$")
RE_H4_APPENDIX = re.compile(rf"^\s*[{PUNCT_WS}]*(é™„è®°|é™„[:ï¼š])")

# ==========================================================
# æ ‡é¢˜è¯†åˆ«å‡½æ•°
# ==========================================================
def detect_headings(lines):
    results = []
    for line in lines:
        text = line.rstrip("\n")
        stripped = text.strip()
        if not stripped:
            results.append({"level": None, "title": None, "text": line})
            continue

        core = RE_ALL_HASHES.sub("", stripped)
        lvl, title = None, None

        for p in H1_PATTERNS:
            if p.match(core):
                lvl, title = 1, core
                break

        if not lvl:
            for p in H2_PATTERNS:
                if p.match(core):
                    lvl, title = 2, core
                    break

        if not lvl:
            m = RE_H3_NUM_TITLE.match(core)
            if m:
                num = int(m.group("num"))
                title_part = m.group("title")
                if num <= 650 and len(title_part) <= 15:
                    lvl, title = 3, core

        if not lvl and RE_H4_APPENDIX.match(core):
            lvl, title = 4, core

        results.append({"level": lvl, "title": title, "text": line})
    return results

# ==========================================================
# ä¿®æ­£ç‰ˆï¼šå¸¦å•ä¸ª#ä¸”ä¸åŒ¹é…H1è§„åˆ™ â†’ åŠ ç²—
# ==========================================================
def emphasize_unmatched_h1(results):
    emphasized = []
    for item in results:
        line = item["text"].rstrip("\n")

        if re.match(r"^\s*#(?!#)", line):
            core = re.sub(r"^\s*#\s*", "", line).strip()
            matched_h1 = any(p.match(core) for p in H1_PATTERNS)
            if (not item["level"]) or (item["level"] == 1 and not matched_h1):
                item["text"] = f"**{core}**\n"
                item["level"] = None
                emphasized.append(core)
    return results, emphasized

# ==========================================================
# è¾“å‡ºä¸ç»Ÿè®¡
# ==========================================================
def export_results(results, emphasized):
    counts = {1:0, 2:0, 3:0, 4:0}
    samples = {1:[], 2:[], 3:[], 4:[]}
    out_lines = []

    for item in results:
        lvl, title, line = item["level"], item["title"], item["text"].rstrip("\n")
        if lvl:
            out_lines.append("#" * lvl + " " + title + "\n")
            counts[lvl] += 1
            if len(samples[lvl]) < DEBUG_SHOW_PER_LEVEL:
                samples[lvl].append(title)
        else:
            out_lines.append(line + "\n")

    # ğŸ§© æ›¿æ¢ï¼šä½¿ç”¨ç»Ÿä¸€çš„ save_text å‡½æ•°è¾“å‡ºç»“æœ
    save_text(OUTPUT_TARGET, "".join(out_lines))

    rows = [{
        "file": os.path.basename(INPUT_PATH),
        "H1": counts[1],
        "H2": counts[2],
        "H3": counts[3],
        "H4": counts[4],
        "Emphasized_H1": len(emphasized),
        "TOTAL": sum(counts.values())
    }]
    with open(CSV_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["file","H1","H2","H3","H4","Emphasized_H1","TOTAL"])
        writer.writeheader()
        writer.writerows(rows)

    with open(CSV_EMPH_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["Emphasized_H1_Text"])
        for t in emphasized:
            writer.writerow([t])

    summary = "ï¼Œ".join([f"H{lvl}={counts[lvl]}ï¼ˆä¾‹ï¼š{'ï¼›'.join(samples[lvl])}ï¼‰" for lvl in range(1,5) if counts[lvl]])
    print(f"âœ… æ ‡é¢˜è¯†åˆ«å®Œæˆ | {summary} | åŠ ç²—H1={len(emphasized)}")

    # âœ… æ–°å¢ï¼šç»Ÿä¸€æ ¼å¼åŒ–è¾“å‡ºé˜¶æ®µæ€»ç»“
    log_summary("æ ‡é¢˜ç»“æ„è§„èŒƒåŒ–", INPUT_PATH, OUTPUT_TARGET)

# ==========================================================
# ä¸»æµç¨‹
# ==========================================================
def main():
    # âœ… æ–°å¢ï¼šé˜¶æ®µæ—¥å¿— + æ–‡ä»¶åŠ è½½
    log_stage("é˜¶æ®µ1ï¼šåŠ è½½ä¸æ ‡å‡†åŒ–")
    text = load_text(INPUT_PATH)              # ğŸ§© æ›¿æ¢ open()
    lines = text.splitlines(True)

    # âœ… æ–°å¢ï¼šé˜¶æ®µæ—¥å¿—è¾“å‡º
    log_stage("é˜¶æ®µ2ï¼šé€è¡Œè¯†åˆ« H1~H4")
    results = detect_headings(lines)

    log_stage("é˜¶æ®µ3ï¼šå¤„ç†å¸¦#ä½†ä¸åœ¨H1è§„åˆ™çš„è¡Œ â†’ åŠ ç²—")
    results, emphasized = emphasize_unmatched_h1(results)

    log_stage("é˜¶æ®µ4ï¼šè¾“å‡º Markdown ä¸ CSV")
    export_results(results, emphasized)

if __name__ == "__main__":
    main()
# åˆ›å»ºæ—¶é—´: 2025/10/31 10:19
