# åˆ›å»ºæ—¶é—´: 2025/10/15 11:17
# -*- coding: utf-8 -*-
"""
Markdown æ¸…æ´—è„šæœ¬ v4
--------------------------------
åŠŸèƒ½ï¼š
1ï¸âƒ£ æ£€æµ‹æˆ–æ¸…ç†å„ç±»é“¾æ¥ï¼›
2ï¸âƒ£ å„çº§æ ‡é¢˜å‰åæœ‰ä¸”ä»…æœ‰ä¸€ä¸ªç©ºè¡Œï¼›
3ï¸âƒ£ æ™®é€šæ®µè½ä¹‹é—´ä¹Ÿæœ‰ä¸”ä»…æœ‰ä¸€ä¸ªç©ºè¡Œã€‚
"""

import re
from pathlib import Path

# ===== é…ç½® =====
INPUT_PATH  =r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\è€é»‘è§£æç‰ˆæœ¬\æ­£å¼æµ‹è¯•\6.5_Chinese Folk Tales_sichuan_cleaned.md"
OUTPUT_PATH = r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\è€é»‘è§£æç‰ˆæœ¬\æ­£å¼æµ‹è¯•\6.6_Chinese Folk Tales_sichuan_cleaned.md"

REMOVE_LINKS = False   # True=ä»…æ£€æµ‹æ‰“å°; False=ç§»é™¤é“¾æ¥
# =================

# --- æ­£åˆ™å®šä¹‰ ---
RE_HEADING = re.compile(r"^\s*#{1,6}\s+.*$")
RE_LINK_MD = re.compile(r"\[([^\]]+)\]\(([^)]+)\)")    # [text](url)
RE_LINK_ANGLE = re.compile(r"<(https?://[^>]+)>")      # <http://xxx>
RE_LINK_BARE = re.compile(r"https?://[^\s)\]]+")       # è£¸url
RE_EMPTY = re.compile(r"^[\s\u200b\u200c\u200d\uFEFF]*$")


# === åŠŸèƒ½æ¨¡å— ===

def detect_links(text: str):
    """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„é“¾æ¥"""
    md_links = RE_LINK_MD.findall(text)
    angle_links = RE_LINK_ANGLE.findall(text)
    bare_links = RE_LINK_BARE.findall(text)

    total = len(md_links) + len(angle_links) + len(bare_links)
    print(f"\nğŸ” æ£€æµ‹åˆ° {total} ä¸ªé“¾æ¥ï¼š")

    if md_links:
        print(f"  â€¢ Markdown é“¾æ¥ {len(md_links)} ä¸ªï¼š")
        for t, url in md_links[:10]:
            print(f"    [{t}]({url})")
    if angle_links:
        print(f"  â€¢ å°–æ‹¬å·é“¾æ¥ {len(angle_links)} ä¸ªï¼ˆç¤ºä¾‹å‰3ä¸ªï¼‰ï¼š")
        for u in angle_links[:3]:
            print(f"    <{u}>")
    if bare_links:
        print(f"  â€¢ è£¸URL {len(bare_links)} ä¸ªï¼ˆç¤ºä¾‹å‰3ä¸ªï¼‰ï¼š")
        for u in bare_links[:3]:
            print(f"    {u}")

    print("\nâœ… å½“å‰ä¸ºæ£€æµ‹æ¨¡å¼ï¼Œä¸æ‰§è¡Œåˆ é™¤ã€‚")


def remove_links_from_text(text: str) -> str:
    """ç§»é™¤æ‰€æœ‰ç±»å‹çš„é“¾æ¥"""
    text = RE_LINK_MD.sub(r"\1", text)
    text = RE_LINK_ANGLE.sub("", text)
    text = RE_LINK_BARE.sub("", text)
    return text


def normalize_blank_lines(lines):
    """
    ç¡®ä¿æ ‡é¢˜ä¸æ­£æ–‡æ®µè½å‰åç©ºè¡Œä»…1è¡Œ
    - æ ‡é¢˜å‰åä¿è¯1è¡Œç©ºè¡Œï¼›
    - æ®µè½ä¹‹é—´ä¿è¯1è¡Œç©ºè¡Œï¼›
    """
    output = []
    prev_blank = True  # æ–‡ä»¶å¼€å¤´è§†ä¸ºç©ºè¡Œ
    for i, line in enumerate(lines):
        stripped = line.rstrip("\r\n")

        # æ ‡é¢˜è¡Œ
        if RE_HEADING.match(stripped):
            if not prev_blank:
                output.append("\n")
            output.append(stripped + "\n")
            output.append("\n")
            prev_blank = True
            continue

        # ç©ºè¡Œ
        if RE_EMPTY.match(stripped):
            if not prev_blank:
                output.append("\n")
                prev_blank = True
            continue

        # æ™®é€šæ­£æ–‡
        output.append(stripped + "\n")
        prev_blank = False

    if not output or not output[-1].strip():
        pass
    else:
        output.append("\n")

    return output


# === ä¸»ç¨‹åº ===

def main():
    ip = Path(INPUT_PATH)
    if not ip.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{ip}")

    text = ip.read_text(encoding="utf-8", errors="ignore")

    if REMOVE_LINKS:
        # ä»…æ£€æµ‹ & æ‰“å°é“¾æ¥
        detect_links(text)
        return

    # çœŸæ­£æ¸…ç†æ¨¡å¼
    print("ğŸ§¹ æ‰§è¡Œé“¾æ¥æ¸…ç† + ç©ºè¡Œè§„èŒƒåŒ– ...")
    text = remove_links_from_text(text)
    lines = text.splitlines(True)
    formatted_lines = normalize_blank_lines(lines)
    Path(OUTPUT_PATH).write_text("".join(formatted_lines), encoding="utf-8")

    print(f"\nâœ… å·²æ¸…ç†å¹¶è¾“å‡ºç»“æœï¼š{OUTPUT_PATH}")


if __name__ == "__main__":
    main()
