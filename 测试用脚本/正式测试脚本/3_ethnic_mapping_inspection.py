# åˆ›å»ºæ—¶é—´: 2025/10/10 11:35
# -*- coding: utf-8 -*-
"""
æ‰«æ Markdownï¼Œæ‰¾å‡ºæ‰€æœ‰ä»¥â€œæ—â€ç»“å°¾çš„ä¸­æ–‡è¯ï¼›
å…è®¸â€œæ—â€å‰çš„æ±‰å­—ä¹‹é—´æºæ‚ç©ºæ ¼ï¼ˆå¦‚â€œç»´ å¾ å°” æ—â€â€œå½ æ—â€ï¼‰ï¼›
åŒ¹é…åä¼šå»é™¤å†…éƒ¨ç©ºç™½å†ä¸æ°‘æ—æ˜ å°„è¡¨æ¯”å¯¹ï¼Œæœªå‘½ä¸­çš„å¯¼å‡º CSVã€‚
"""

import os
import re
import json
import csv
import difflib

# ====== ç¡¬ç¼–ç è·¯å¾„ ======
mapping_path = r"D:\pythonprojects\folktales\data\mappings\ethnic_map.json"   # å½¢å¦‚ {"æ±‰æ—":"han", "å£®æ—":"zhuang", ...}
input_paths = [
    r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\è€é»‘è§£æç‰ˆæœ¬\æ­£å¼æµ‹è¯•\Chinese Folk Tales_sichuan.md",
    "input2.md",
    "input3.md",
]
output_csv = r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\è€é»‘è§£æç‰ˆæœ¬\æ­£å¼æµ‹è¯•\ethnic_unknowns_1.csv"


# ====== å¯è°ƒå‚æ•° ======
MIN_PRE_CHARS = 1      # æŠ“â€œæ—â€å‰è‡³å°‘å‡ ä¸ªå­—ï¼ˆç»Ÿè®¡æ—¶ä¸è®¡ç©ºæ ¼ï¼‰
MAX_PRE_CHARS = 5      # æŠ“â€œæ—â€å‰æœ€å¤šå‡ ä¸ªå­—ï¼ˆä¸è®¡ç©ºæ ¼ï¼›ç”¨äºæœ€é•¿ä¼˜å…ˆï¼‰
MAX_CH_WORD    = 12    # å…è®¸çš„æœ€å¤§â€œæ±‰å­—æˆ–ç©ºæ ¼â€é•¿åº¦ï¼ˆå«ç©ºæ ¼ï¼Œä¿é™©æ”¾å®½ï¼‰
FUZZY_TOPN     = 3
FUZZY_CUTOFF   = 0.6

# å¸¸è§éœ€è¦æ’é™¤çš„â€œéæ°‘æ—è¯â€ï¼ˆæ¯”è¾ƒæ—¶ä¼šå…ˆå»ç©ºæ ¼ï¼‰
EXCLUDE_TERMS = {
    "æ°‘æ—", "æ°æ—", "å®¶æ—", "éƒ¨æ—", "å®—æ—", "æ—è°±", "æ—ç¾¤", "æ—äºº"
}

# ====== æ­£åˆ™ï¼šå…è®¸â€œæ±‰å­— æˆ– ç©ºç™½â€åå¤ï¼Œæœ€åä»¥â€œæ—â€ç»“å°¾ ======
# è¯´æ˜ï¼š
# - \s ä¼šè¦†ç›–åŠè§’ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€æ¢è¡Œï¼›æˆ‘ä»¬å†é¢å¤–å¤„ç†å…¨è§’ç©ºæ ¼ \u3000 å’Œ NBSP \xa0
CHN = r"[\u4e00-\u9fff]"
SPACE_CLASS = r"(?:\s|\u3000|\xa0)"
CHN_OR_SPACE = rf"(?:{CHN}|{SPACE_CLASS})"
PATTERN = re.compile(rf"({CHN_OR_SPACE}{{1,{MAX_CH_WORD}}}æ—)")

def normalize_spaces(s: str) -> str:
    """ç»Ÿä¸€ç©ºç™½ï¼šæŠŠå„ç±»ç©ºç™½éƒ½å½“ç©ºæ ¼ï¼Œå†å»æ‰æ‰€æœ‰ç©ºç™½"""
    # å…ˆæŠŠå…¨è§’ç©ºæ ¼ä¸ NBSP å½’ä¸€ä¸ºæ™®é€šç©ºæ ¼ï¼Œå†åˆ å»æ‰€æœ‰ç©ºæ ¼
    return re.sub(r"\s+", "", s.replace("\u3000", " ").replace("\xa0", " "))

def load_mapping(path):
    with open(path, "r", encoding="utf-8") as f:
        mp = json.load(f)
    mapping_full = {}
    for k, v in mp.items():
        if not k:
            continue
        k = normalize_spaces(k.strip())
        if k.endswith("æ—"):
            mapping_full[k] = v
        else:
            mapping_full[k + "æ—"] = v
    # åå‘ï¼ˆå»â€œæ—â€ï¼‰ç´¢å¼•
    nozu_to_full = {}
    for k in mapping_full.keys():
        base = k[:-1] if k.endswith("æ—") else k
        nozu_to_full[base] = k
    return mapping_full, nozu_to_full

def iter_zu_words(line):
    """åœ¨ä¸€è¡Œé‡Œè¿­ä»£å…è®¸ç©ºæ ¼å¤¹æ‚çš„ '...æ—' ç‰‡æ®µ"""
    for m in PATTERN.finditer(line):
        word_raw = m.group(1)         # åŸæ ·ï¼ˆå¯èƒ½å«ç©ºæ ¼ï¼‰
        start, end = m.span(1)
        yield word_raw, start, end

def best_map_match(word_raw, mapping_full, nozu_to_full):
    """
    ä½¿ç”¨â€œæœ€é•¿ä¼˜å…ˆâ€åœ¨æ¸…æ´—åçš„è¯ä¸ŠåŒ¹é…ï¼š
    - å…ˆå»é™¤å†…éƒ¨ç©ºç™½å¾—åˆ° wordï¼ˆå½¢å¦‚ 'æŸ¯å°”å…‹å­œæ—' æˆ– 'å½æ—'ï¼‰
    - åœ¨ æ— å‰æŠ“å– MIN..MAX ä¸ªâ€œæ±‰å­—ï¼ˆä¸è®¡ç©ºæ ¼ï¼‰â€å½¢æˆå€™é€‰å­ä¸²ï¼ˆå«â€œæ—â€ï¼‰
    """
    word = normalize_spaces(word_raw)
    if len(word) < 2 or not word.endswith("æ—"):
        return False, None, None

    # æ—å‰çš„çº¯æ±‰å­—é•¿åº¦
    han_len = len(word) - 1  # æ’é™¤æœ€åä¸€ä¸ªâ€œæ—â€
    # æœ€é•¿ä¼˜å…ˆ
    for pre in range(min(MAX_PRE_CHARS, han_len), MIN_PRE_CHARS - 1, -1):
        cand = word[han_len - pre : ]  # ä»å€’æ•° pre ä¸ªæ±‰å­—åˆ°â€œæ—â€çš„å­ä¸²
        # 1) å®Œæ•´é”®åŒ¹é…
        if cand in mapping_full:
            return True, cand, mapping_full[cand]
        # 2) é€€åŒ–ï¼šä¸å«â€œæ—â€çš„é”®ï¼ˆå…œåº•ï¼‰
        base = cand[:-1]
        if base in nozu_to_full:
            full_key = nozu_to_full[base]
            return True, full_key, mapping_full[full_key]
    return False, None, None

def make_context(line, start, end, span=20):
    left = line[max(0, start - span): start]
    mid  = line[start:end]
    right= line[end: end + span]
    return f"â€¦{left}[{mid}]{right}â€¦".replace("\n", " ")

def fuzzy_suggest(target_raw, candidates, topn=3, cutoff=0.6):
    target = normalize_spaces(target_raw)
    return difflib.get_close_matches(target, candidates, n=topn, cutoff=cutoff)

def main():
    if not any(p for p in input_paths):
        print("âš ï¸ æœªæä¾›ä»»ä½•è¾“å…¥è·¯å¾„ã€‚")
        return
    if not os.path.exists(mapping_path):
        print(f"âŒ æ˜ å°„è¡¨ä¸å­˜åœ¨ï¼š{mapping_path}")
        return

    mapping_full, nozu_to_full = load_mapping(mapping_path)
    mapping_keys = list(mapping_full.keys())

    rows = []
    unknown_counter = 0

    for path in input_paths:
        if not path:
            continue
        if not os.path.exists(path):
            print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼š{path}")
            continue

        with open(path, "r", encoding="utf-8") as f:
            lines = f.readlines()

        for lineno, line in enumerate(lines, start=1):
            for word_raw, s, e in iter_zu_words(line):
                word_norm = normalize_spaces(word_raw)
                # æ’é™¤é¡¹ï¼šå…ˆå»ç©ºç™½å†æ¯”è¾ƒ
                if word_norm in EXCLUDE_TERMS:
                    continue

                matched, key, code = best_map_match(word_raw, mapping_full, nozu_to_full)
                if matched:
                    continue  # å‘½ä¸­æ˜ å°„åˆ™ä¸å¯¼å‡º

                # cand2/cand3 ç”¨å»ç©ºç™½åçš„æœ«å°¾ 2/3 å­—ï¼ˆå«â€œæ—â€ï¼‰
                cand2 = word_norm[-2:] if len(word_norm) >= 2 else word_norm
                cand3 = word_norm[-3:] if len(word_norm) >= 3 else word_norm

                sugg = fuzzy_suggest(word_raw, mapping_keys, topn=FUZZY_TOPN, cutoff=FUZZY_CUTOFF)

                rows.append({
                    "file": os.path.basename(path),
                    "line": lineno,
                    "word_raw": word_raw,          # åŸæ ·ï¼ˆä¿ç•™ç©ºæ ¼ï¼Œä¾¿äºå®šä½ OCR é—®é¢˜ï¼‰
                    "word_norm": word_norm,        # å»ç©ºç™½åï¼ˆç”¨äºæ¯”å¯¹/ä¿®è®¢ï¼‰
                    "cand2": cand2,
                    "cand3": cand3,
                    "context": make_context(line, s, e, span=20),
                    "suggest_1": sugg[0] if len(sugg) > 0 else "",
                    "suggest_2": sugg[1] if len(sugg) > 1 else "",
                    "suggest_3": sugg[2] if len(sugg) > 2 else "",
                })
                unknown_counter += 1

    if rows:
        with open(output_csv, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=[
                "file", "line", "word_raw", "word_norm", "cand2", "cand3",
                "context", "suggest_1", "suggest_2", "suggest_3"
            ])
        # write header + rows
            writer.writeheader()
            writer.writerows(rows)
        print(f"ğŸ¯ å…±å‘ç° {unknown_counter} å¤„æœªæ˜ å°„çš„â€œ*æ—â€è¯ï¼ˆå·²æ”¾å®½ç©ºæ ¼è§„åˆ™ï¼‰ï¼Œå·²å¯¼å‡ºï¼š{output_csv}")
    else:
        print("âœ… æœªå‘ç°æœªæ˜ å°„çš„â€œ*æ—â€è¯ã€‚")

if __name__ == "__main__":
    main()
