# -*- coding: utf-8 -*-
# Created on: 2025-10-27
# Version: v2025.04
"""
æ°‘æ—åç§°æ‰¹é‡å¤„ç†å·¥å…·ï¼ˆéªŒè¯ / æ›¿æ¢ ä¸€ä½“åŒ–ï¼‰
-------------------------------------------------
âœ… VALIDATION_MODE = True  â†’ æ£€æŸ¥æ°‘æ—åç§°åˆæ³•æ€§ï¼Œä»…è¾“å‡ºCSVæŠ¥å‘Š
âœ… VALIDATION_MODE = False â†’ æ‰§è¡Œæ‰¹é‡æ›¿æ¢ï¼Œè¦†ç›–åŸæ–‡ä»¶å¹¶æ‰“å°æ›¿æ¢ç»Ÿè®¡
"""

import re
import csv
from pathlib import Path

# ===== Configuration =====
INPUT_PATH  = r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\åˆ†å·æ¸…æ´—\yunnan\6.7.2_Chinese Folk Tales_yunnan.md"
OUTPUT_CSV  = r"I:\ä¸­å›½æ°‘é—´ä¼ ç»Ÿæ•…äº‹\åˆ†å·æ¸…æ´—\yunnan\6.7.2.1_invalid_ethnicity_report.csv"

# æ§åˆ¶æ¨¡å¼ï¼šTrue=éªŒè¯åˆæ³•æ€§ï¼›False=æ›¿æ¢ä¿®æ­£
VALIDATION_MODE = True
# ==========================

# ===== æ°‘æ—åˆæ³•æ€§å­—å…¸ =====
VALID_ETHNICITIES = {
    "æ±‰æ—","å£®æ—","å›æ—","æ»¡æ—","ç»´å¾å°”æ—","è‹—æ—","å½æ—","åœŸå®¶æ—","è—æ—","è’™å¤æ—",
    "å¸ƒä¾æ—","ä¾—æ—","ç‘¶æ—","æœé²œæ—","ç™½æ—","å“ˆå°¼æ—","å“ˆè¨å…‹æ—","é»æ—","å‚£æ—","ç•²æ—",
    "å‚ˆåƒ³æ—","ä»¡ä½¬æ—","ä¸œä¹¡æ—","é«˜å±±æ—","æ‹‰ç¥œæ—","æ°´æ—","ä½¤æ—","çº³è¥¿æ—","ç¾Œæ—","åœŸæ—",
    "ä»«ä½¬æ—","é”¡ä¼¯æ—","æŸ¯å°”å…‹å­œæ—","è¾¾æ–¡å°”æ—","æ™¯é¢‡æ—","æ¯›å—æ—","æ’’æ‹‰æ—","å¸ƒæœ—æ—","å¡”å‰å…‹æ—",
    "é˜¿æ˜Œæ—","æ™®ç±³æ—","é„‚æ¸©å…‹æ—","æ€’æ—","äº¬æ—","åŸºè¯ºæ—","å¾·æ˜‚æ—","ä¿å®‰æ—","ä¿„ç½—æ–¯æ—","è£•å›ºæ—",
    "ä¹Œå­œåˆ«å…‹æ—","é—¨å·´æ—","é„‚ä¼¦æ˜¥æ—","ç‹¬é¾™æ—","å¡”å¡”å°”æ—","èµ«å“²æ—","çå·´æ—"
}

# ===== æ›¿æ¢æ˜ å°„ =====
REPLACE_MAP = {
    "ä¿ä¿æ—": "å‚ˆåƒ³æ—",
    "ä¿åº·æ—": "å‚ˆåƒ³æ—",
    "å€®å€®æ—": "å‚ˆåƒ³æ—",
    "ä½•æ˜Œæ—": "é˜¿æ˜Œæ—",
    "æ™®ç¦¾æ—": "æ™®ç±³æ—",
    "èŠ¯æ—": "æ€’æ—",
    "è‹—ç„•": "è‹—æ—",
}
# ==========================

# ===== æ­£åˆ™æ¨¡å¼ =====
RE_HEADING = re.compile(r"^(#{1,6})\s*\d{1,4}[\.\ã€,ï¼Œï¼ï¼š:\s]*.+$")
RE_ETHNICITY_LINE = re.compile(r"^\s*>\s*([\u4e00-\u9fa5â€”â€”\s]+)$")
# ==========================


def clean_ethnicity(raw: str) -> str:
    """æ¸…ç†æ°‘æ—åç§°ä¸­çš„æ‚å­—ç¬¦"""
    return re.sub(r"[^\u4e00-\u9fa5â€”â€”]", "", raw or "").strip()


def check_ethnicity(file_path: Path):
    """æ£€æŸ¥Markdownæ–‡ä»¶ä¸­ '>' å¼€å¤´çš„æ°‘æ—åç§°æ˜¯å¦åˆæ³•"""
    lines = file_path.read_text(encoding="utf-8", errors="ignore").splitlines()
    invalid = []
    current_heading = "ï¼ˆæ— æ ‡é¢˜ï¼‰"

    for i, raw in enumerate(lines, start=1):
        line = raw.strip()
        if RE_HEADING.match(line):
            current_heading = line
            continue
        if not line.startswith(">"):
            continue
        m = RE_ETHNICITY_LINE.match(line)
        if not m:
            continue
        ethnicity = clean_ethnicity(m.group(1))
        if not ethnicity or ethnicity == "â€”â€”":
            continue
        if ethnicity not in VALID_ETHNICITIES:
            invalid.append({
                "heading": current_heading,
                "line_no": i,
                "ethnicity": ethnicity,
                "status": "âŒ Not in dict"
            })
    return invalid


def export_csv(invalid_list, output_path):
    """å°†æ— æ•ˆæ°‘æ—åç§°å¯¼å‡ºä¸ºCSV"""
    with open(output_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["Heading", "LineNo", "Ethnicity", "Status"])
        for item in invalid_list:
            writer.writerow([item["heading"], item["line_no"], item["ethnicity"], item["status"]])
    print(f"\nğŸ§¾ å·²è¾“å‡ºæŠ¥å‘Šï¼š{output_path}")


def replace_ethnicities(text: str, mapping: dict):
    """æ‰§è¡Œæ‰¹é‡æ›¿æ¢å¹¶ç»Ÿè®¡æ›¿æ¢æ¬¡æ•°"""
    stats = {}
    for old, new in sorted(mapping.items(), key=lambda x: len(x[0]), reverse=True):
        pattern = re.compile(re.escape(old))
        matches = len(pattern.findall(text))
        if matches > 0:
            text = pattern.sub(new, text)
            stats[old] = matches
    return text, stats


def main():
    ip = Path(INPUT_PATH)
    if not ip.exists():
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {ip}")

    if VALIDATION_MODE:
        # --- æ¨¡å¼1ï¼šåˆæ³•æ€§éªŒè¯ ---
        invalid_entries = check_ethnicity(ip)
        print("====== æ°‘æ—åˆæ³•æ€§æ£€æµ‹ ======")
        if not invalid_entries:
            print("âœ… æ‰€æœ‰æ°‘æ—åç§°å‡åœ¨åˆæ³•å­—å…¸ä¸­ã€‚")
        else:
            print(f"âš ï¸ æ£€æµ‹åˆ° {len(invalid_entries)} ä¸ªéæ³•æ°‘æ—åç§°ï¼š")
            for item in invalid_entries:
                print(f"{item['line_no']:>5} | {item['heading']} | {item['ethnicity']}")
            export_csv(invalid_entries, Path(OUTPUT_CSV))
        print("=================================")
    else:
        # --- æ¨¡å¼2ï¼šæ›¿æ¢ä¿®æ­£ ---
        text = ip.read_text(encoding="utf-8", errors="ignore")
        replaced_text, stats = replace_ethnicities(text, REPLACE_MAP)
        ip.write_text(replaced_text, encoding="utf-8")

        if stats:
            total = sum(stats.values())
            for old, count in stats.items():
                print(f"{old} â†’ {REPLACE_MAP[old]} ï¼š{count} å¤„")
            print(f"æ€»è®¡æ›¿æ¢ï¼š{total} å¤„")
        else:
            print("æœªæ£€æµ‹åˆ°å¯æ›¿æ¢çš„æ°‘æ—åç§°ã€‚")


if __name__ == "__main__":
    main()
# åˆ›å»ºæ—¶é—´: 2025/10/28 14:55
